== Camel K and Openshift Serverless Eventing

Author: Phil Prosser (feedback to pprosser@redhat.com)

=== Introduction

.OpenShift Serverless
****
Openshift Serverless, based on Knative is the serverless technology that was introduced in Openshift 4.2. Openshift Serverless enables Pods running on Openshift to be scaled to 0 therefore taking zero processing power. Only when called, Openshift Serverless will scale the Pod up on demand before processing the request. Openshift Serverless also has the ability to autoscale based on load before eventually scaling back to zero when no requests are being received. 

Openshift Serverless supports "Serving" and "Eventing"

At the time of writing, Serving is in technology preview, and Eventing is in Developer Preview

"Serving" enables request/response workloads, and Eventing enables asynchronous event based workloads using cloudevents. In this lab, we are going to look at eventing, and how easy it is to integration with Camel K.
****

Whilst Openshift Serverless has it's own cli (kn), the purpose of this lab is to show the integration of Camel K into Openshift Serverless.

=== Openshift Serverless and the Operator Lifecycle Manager

.Openshift Serverless and the Operator Lifecycle Manager
****
Openshift Serverless uses the Operator Lifecycle manager, this means that its operator and Custom Resource Definitions (CRDs) will be added to Openshift via "OLM". Once created, the new CRDs will extend the Openshift data model allowing Openshift Serverless to be managed using the standard ‘oc’ command. Installing operators requires a higher cluster privilege so the presenter will have already set these up for you.
****

=== Creating the pre-requisites for the chapter

Before we can create an integration, we need to check that the camel-k integration added in a previous chapter is still active

In the terminal window, type

[source]
----
cd /workspace/workshop4/camelfiles/camelkplatform
oc apply -f integrationplatform.yaml
----

This will either create the integration platform or, if it is still active, indicate it is unchanged

=== Create Knative Messaging Channel 

Openshift Serverless uses Knative eventing, Knative eventing is a loosely couple asynchronous architecture allowing event producers to send an event to one or more event consumers. Event Consumers can be scaled to 0 when no events are folowing through the system.

By default, Knative uses an in memory messaging channel. In this lab we will configure 2 of these channels to use with Camel K

Options are also available to replace in memory messaging with other event sources such as the Kafka Channel. By combining Camel K and Red Hat AMQ Streams (Red Hats Kafka Implementation) on Openshift you create a powerful / reliable cloud native eventing platform for your applications.

In the browser terminal window type the following:

[source]
----
cd /workspace/examples/knative
oc apply -f messages-channel.yaml
oc apply -f words-channel.yaml
----

To make sure the channels have been created correctly type:

[source]
----
oc get inmemorychannel
----

You should see a screenshot like the one below

image::camekknative-4.png[InMemory Channels Ready]

You are looking for 'READY' to be 'True'

=== Deploy the Integrations

.Introduction to the integrations that we will use
****
Now that we have deployed 2 message channels, we will deploy 3 Camel K Integrations. 'feed.groovy' will generate a simple sentence every 3 seconds, and send this to the 'message channel', 'splitter.groovy' will subscribe to the 'message channel', take the message, split the message into individual words before sending the individual words to 'words channel'. Finally, 'printer.groovy' will subscribe to the 'words.channel', read the words from the channel and print them to the output log.

The flow looks like:

feed -> message channel -> spilter -> words channel -> printer

****

In the terminal window, deploy the 3 integrations

[source]
----
kamel run feed.groovy
kamel run splitter.groovy
kamel run printer.groovy
----

First go to the Administrator view in the OpenShift console - at the top left make sure the view is set to Administrator

Go to Workloads/Pods. As you are using a single namespace for the workshop this should display the active Pods in sandboxX, where X is your user number

Watch as the integrations are created using builder and deployment containers. This may take a little while. 

image::camekknative-11.png[Containers building]

Once it has finished deploying the integrations you will have three Pods active as shown similar to the screenshot below (ignore the devex Pod, this is your terminal Pod)

image::camekknative-12.png[Containers Complete]

Now go to the developer view in the OpenShift Console

Now that all 3 of the Integrations are deployed, the topology view should look like the screenshot below

image::camekknative-5.png[Integrations running]

Each of the integrations is producing log information. 

At the time of writing, there is no easy way to view the pod log files of a knative service in the console, so in the developer view click on Advanced/Project Details and choose Workloads

image::camekknative-6.png[Viewing overview of running Integration]

For each workload, you should see a '1 of 1 pods' on the right hand side. 'Click' on the '1 of 1 pods'.

You should see a screen similar to the one below

image::camekknative-7.png[Running Pod]

'Click' on the Pod name on the left e.g. printer-xxxxxxxxxxxx

This should show you a screen similar to the one below

image::camekknative-8.png[Pod Details]

'Click' on 'Logs' to view the log for the pod. It should look something like the one below

image::camekknative-9.png[Pod Details]

Repeat the steps above for the other 2 Integrations if you like.

=== Knative in action

Make sure you are in the developer view of the console, looking at the Topology view before continuing

The 2 Integrations "hooked" into Knative Eventing are the 'spilter' and 'printer' integrations (you can visually see this on the topology view). 

Let's see if the promise of scale to zero works.

To stop the integrations, we need to stop messages arriving at the "messages.channel". To do this, we need to stop the feed integration.

In the terminal browser window, type

[source]
----
kamel delete feed
----

Go back to the topology view, you will notice that the feed integration has gone. 

image::camekknative-13.png[No Feed]

Show some patience now, keep lookng at the topology view, we are waiting (and hoping!) that the integrations scale down to zero.

You will know when this starts as the rings around the circles will change from the normal blue to a very dark blue, before going white. Once they are white, the integrations are scaled to zero just like the screenshot below

image::camekknative-10.png[Scaled to zero]

To wake the Integrations up again, redeploy the 'feed' integration.

[source]
----
kamel run feed.groovy
----

Go back to the topology view and you should see the 'feed' integration redeploy, and the 'spillter' and 'printer' integrations awake from their slumber.

This shows the potential for effective serverless behaviour by the down-scaling of unused applications, combined with the ease of Camel-K integrations.

To clean up before the next chapter run the following commands in the terminal:

[source]
----
kamel delete feed
kamel delete splitter
kamel delete printer
----



