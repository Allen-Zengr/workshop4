:hide-uri-scheme:
== OpenShift Service Mesh

Author: Mark Roberts (feedback to mroberts@redhat.com)

=== Introduction




==== The Istio ingress gateway

All traffic entering the cluster, for all applications managed by the service mesh, uses the same istio ingress gateway. The gateway URL can be found from the istio-ingressgateway resource within the istio-system namespace.

The command below will show the hostname to be used for all interaction with applications managed by the service mesh:

[source]
----
oc get route istio-ingressgateway -n istio-system -o jsonpath='{.spec.host}{"\n"}'
----

Save the gateway URL as an environment variable to be re-used in further commands by executing :

[source]
----
export SM_GATEWAY=$(oc get route istio-ingressgateway -n istio-system -o jsonpath='{"http://"}{.spec.host}')
echo $SM_GATEWAY 

IS THIS NEEDED ???
----

==== Create a new project for the service mesh activity

[source]
----
oc new-project service-mesh-X 
----

(Where X is your user number)

Not all projects are required to be managed by service mesh. As a result you need to add the project that you just created to the service mesh control plane so that the sidecar containers will be injected into the pods. If you have not downloaded the project assets from GitHub already during the workshop, then download them now by executing the following command in the OpenShift terminal window : 

[source]
----
cd /workspace
git clone https://github.com/utherp0/workshop4.git
cd workshop4/attendee/service-mesh
----

To add the current project as a service mesh member within the control plane called 'istio-system' execute the command :

[source]
----
oc create -f servicemeshmember.yaml
----

=== Phase 1

The micro-service based application that you are about to create is very simple and uses a rest interface that can be asked to call another downstream version of itself. This can continue for as many application instances as needed to illustrate the features of the service mesh. 

To create the first application instance do the following :

[source]
----
cd phase1
oc create -f layer1.yaml --save-config
----

Switch to the web user interface and select the developer view for your current project. Select the topology view and you will see the application start to be created. Click on the centre of the blue circle for the application and you should see the fly out menu on the right with details of the service and the running pod. Select the pod and scroll down the details of the pod until you see a section titled 'Containers'. This should show two containers as indicated below which are the layers application container and the Istio sidecar container.

image::service-mesh-01.png[Pod with application container and sidecar container]

Expose the service using a route by executing the following command :

[source]
----
oc expose service/layer1
----

At this point the application has all of the components required for network communication without the use of Istio. The resources required that exist can be viewed with the command :

[source]
---- 
oc get all
----

This will list the following resources :

* deployment
* pod
* replicaset
* service
* route

The route, service and pod are shown in the diagram below to indicate the network communication to the application.

image::service-mesh-02.png[Route, service and application]

Communication to the application will work as expected using the above resources. This can be tested by pasting the following command into the terminal window to make 100 calls to the application, approximately ever 0.2 seconds. 

[source]
----
export ROUTE=$(oc get route -o jsonpath='{.items[0].spec.host}{"/call-layers"}')
for i in {1..100}; do curl $ROUTE; echo ""; sleep .2;done
----

=== Adding Istio capability

To enable the service mesh communication requires further resources to be created. The initial resources to be created are the gateway and the virtual service. The gateway resource identifies a host for which communication should be intercepted and directed to the istio-ingress gateway. The virtual service  acts as a communication director selecting traffic that matches specific criteria for routing to a destination service. The gateway and virtual service yaml content is shown in the diagram below which also shows schematically how the communication is directed.

image::service-mesh-03.png[Istio gateway and virtual service]

Create the gateway and the virtual service with the commands below:

[source]
----
oc create -f gateway-layer1.yaml
oc create -f virtual-service-layer1.yaml
----

==== View the istio related resources

The oc command 'oc get all' is often used to generate a list of all resources within a project. This is fine for listing the deployment configurations, services, replicasets and pods but it does not list the resources used to manage the service mesh. To view the istio related resources use the command below :

[source]
----
oc get istio-io
----

The above command will list the gateway and the virtual service. The virtual service also shows the gateway to which it relates and the hosts for which it is controlling traffic as shown in the example below.

[source]
----
NAME                                        GATEWAYS           HOSTS                                                        AGE
virtualservice.networking.istio.io/layers   [layer1-gateway]   [layer1-layers.apps.cluster-c2d5.c2d5.example.opentlc.com]   54s

NAME                                         AGE
gateway.networking.istio.io/layer1-gateway   63s
----



















=== Service mesh visualisation with Kiali

Red Hat Service mesh includes a component called Kiali which provides a visualisation of the components of the mesh to assist in monitoring and managing the communication processes within a micro-service based application. To find the URL for the Kiali web application enter the command :

[source]
----
oc get route -n istio-system -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.host}{"\n"}'
----

This command will list all of the system services routes for service mesh. Copy the URL for Kiali and paste it into a new browser window.

Press the button to authenticate with your OpenShift credentials and then select the blue '1 application' link in the box labelled with your service-mesh-XX project.

On the left hand side of the Kiali screen select 'Graph and you should see a screen similar to that shown below :

image::service-mesh-04.png[Kiali initial screen]

Press the blue button with the text 'Display unused nodes' and you will see the nodes and services of the application.

You will now see the layer-1 application which is broken out as the service (dotted triangle) and the application (dotted square). Press the legend button to see the key to the objects in the browser window. You will also see that the service has a virtual service associated with it.

Press the display drop down and select the traffic animation option. Back at the terminal window start sending traffic to the service again using the for loop shell script used previously (and repeated below) :

[source]
----
for i in {1..100}; do curl $ROUTE; echo ""; sleep .2;done
----

Switch back to the Kiali window and watch the animation of the traffic flow in the graph. It will take a few seconds for the animation to start, but eventually you will see a screen similar to that which is shown below. 

image::service-mesh-05.png[Kiali traffic animation]

Kiali has a number of sources of information which are selected from the left hand side menu. The animation display is shown on the graph view. If the for loop to send requests to the application has ended then restart it and you may want to change the number of calls to 1000 and change the sleep delay to 0.5 or 1.0 seconds to give more traffic while you explore the user interface.

On the Kiali graph view click on the service (triangle) for layer1 and you will see information about the service on the right hand side panel. The panel shows information about the messages entering and leaving the service. Click on the application for layer1, identified as v1 (square) and the right hand side panel changes to display information about the application.

The top menu of the Graph screen has a number of different viewing modes allowing users to display information on different versions of applications, to only show services or to display the workloads. The versioned application graph is particularly useful as it groups multiple versions of applications together along with their associated services.

The second drop down menu allows for the display of requests per second, request percentage and response time on each green communication line. The request percentage is particularly useful when splitting traffic between versions later.

On the left hand side of the Kiali screen there are options to display information about applications, workloads and services. These displays show useful information on the health of the resource. The Istio Config menu shows information about the istio resources (virtual services and gateways). This is a useful source of information if something is wrong in the configuration of a resource as it will be highlighted clearly as shown below.

image::service-mesh-06.png[Virtual service with error]

==== Creation of further content in the application communication chain

The next phase of building the service mesh is to introduce another application and service. 

Change directory to phase 2 and create the new application for layer 2 with the following commands:

[source]
----
cd ../phase2
oc create -f layer2.yaml --save-config
----

You will see that two deployments are created for the two different versions of layer2, with two pods for each application.

Create the additional virtual service for the component with the commands:

[source]
----
oc create -f virtual-service-layer2.yaml
----

Reconfigure layer1 to send messages to layer2 using the command:

[source]
----
oc apply -f layer1.yaml
----

Switch to the OpenShift browser window and ensure that you are using the developer mode on the top left corner, you have the service-mesh-XX project selected and you are viewing the Topology view. You should see the 'layers' application grouping with layer1-v1 and layer2 (with versions v1 and v2) grouped together within the application group. Click on layer1-v1 and you will see on the fly-out window on the right hand side that it has one pod. This pod contains the running application container and the istio sidecar container too. If you select one of the layer 2 applications you will see that it has 2 replica pods as directed by the layer2.yaml deployment file.

In the OpenShift terminal window restart the for loop to start sending http requests to layer1. You should now see that layer1 is sending requests on to layer 2 and you should see the IP address of the nodes on which those two layers are running as shown below. This also shows the distribution of traffic to the different versions of layer2. 

[source]
----
"layer1 (v1) [10.128.3.13] ----> layer2 (v1) [10.130.3.146]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v2) [10.130.3.147]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v1) [10.131.1.184]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v2) [10.128.3.12]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v1) [10.130.3.146]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v2) [10.130.3.147]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v1) [10.131.1.184]"
----

In most micro-service based applications messages will not conveniently display application versions or IP addresses as in this example application. Consequently Kiali visualisation is very important to show what actually happens in the 'real world'.

Switch to the Kiali browser view and wait until the traffic starts to appear. You may see some extraneous traffic going to nodes that are not in the current project namespaces. These are genuine messages being send to the Istio system to provide the monitoring capabilty. To hide the unwanted nodes use a filter in the 'Hide' text field at the top of the graph and use a filter of "namespace!=service-mesh-XX". Replace XX with your user number and do not include quote characters.

The Kiali graph view (shown below) is currently displaying the communication into layer 1 and then from layer 1 to layer 2. Layer 2 has a virtual service which is governing the conditions under which layer 2 will get any network traffic such as protocol filtering, path filtering etc. In the absence of a destination rule to govern the flow of traffic a (roughly) 50% - 50% split of traffic is seen between version 1 and version 2 of layer 2.

image::service-mesh-07.png[Kiali distribution of traffic to layer 2]

==== Creation of further multi-versioned applications in the communication chain

The next phase of building the service mesh is to introduce a multi-versioned application and service. 

Change directory to phase 3 and create the new application for layer 3 with the following commands:

[source]
----
cd ../phase3
oc create -f layer3.yaml
----

You will see that four deployments are created for the four different versions of layer3. 

Switch to the OpenShift browser window and ensure that you are using the developer mode on the top left corner, you have the service-mesh-XX project selected and you are viewing the Topology view. You should see the 'layers' application grouping now has six micro-services within it. This is shown below:

image::service-mesh-08.png[OpenShift topology view of micro-services]

Under more common circumstances of a development project then names will often be cryptic and it will be hard to gain any understanding of the communication logic, sequence or hierarchy of an overall application. This is when the Kiali visualisation view becomes extremely useful. 

To tie the service mesh together for the different versions of layer3 a virtual service and a destination rule will be used. 

.Virtual Services and Destination Rules
****
Virtual services and destination rules work hand-in-hand to define the routing of traffic. The virtual service is evaluated first and decides how to route traffic to a specific destination and then the destination rule is used to direct the traffic for the identified destination. The virtual service used in this phase is shown below:
[source]
----
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: layer3
spec:
  hosts:
  - layer3
  http:
  - match:
    - uri:
        exact: /call-layers
    - uri:
        exact: /get-info        
    - uri:
        exact: /
  - route:
    - destination:
        host: layer3
        subset: v1
      weight: 50
    - destination:
        host: layer3
        subset: v2
      weight: 30
    - destination:
        host: layer3
        subset: v3
      weight: 20
----

The above will direct http traffic targetted to layer3 (spec: -> hosts: -> layer3) to the destinations subset v1 (50% of traffic), subset v2 (30% of traffic) and subset v3 (20% of traffic). At the present time no traffic is directed to subset v4. 

The destination rule associated with the above virtual service is shown below : 
[source]
----
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: layer3
spec:
  host: layer3
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
  - name: v3
    labels:
      version: v3
----

The destination rule defines to where the different subsets will direct traffic. Subset v1 directs traffic to the pod with the label v1 and subset v2 directs traffic to the pod with the label v2 etc.
****

The command below will display all pods and the labels defined on them:

[source]
----
oc get pods -o jsonpath='{range.items[*]}{.metadata.name}{"  "}{.metadata.labels.version}{"\n"}'
----

The result of the above command will be similar to that shown below:

[source]
----
layer1-v1-5cdbdc64bc-hbm77  v1
layer2-v1-747594d6d9-rd586  v1
layer2-v1-747594d6d9-wlrhr  v1
layer2-v2-7f8b4674cc-vbvt9  v2
layer2-v2-7f8b4674cc-zs9lk  v2
layer3-v1-85db7f87c6-rdz8c  v1
layer3-v2-5649897bbf-6f99m  v2
layer3-v3-769cfb5446-jcs4v  v3
layer3-v4-858765c8c9-m5lzf  v4
----

The above shows that there is 1 version for layer1, 2 versions for layer 2 that are replicated pods (two instances) and 4 versions for layer 3.

Destination rules require a virtual services and there cannot be more destinations than virtual services. For this reason when a destination rule is used the virtual service is either created at the same time or the virtual service already exists. 

[source]
----
oc create -f destination-rule-virtual-service-layer3.yaml
----

In the previous test it was seen that there was a 50% - 50% distribution of traffic to layer 2. The command below will introduce a destination rule and add a distribution clause to the virtual service for layer 2 to distribute the traffic  80% to 20% in favour of version 1.

[source]
----
oc apply -f destination-rule-virtual-service-layer2.yaml
----

Reconfigure layer2 to send messages to layer3 using the command:

[source]
----
oc apply -f layer2.yaml
----

In the OpenShift terminal window restart the for loop to start sending http requests to layer1. You should now see that layer1 is sending requests on to layer 2 which is sending requests on to layer 3 and you should see the IP address of the nodes on which those two layers are running as shown below. You will also see a distribution of workload across layer 3 v1, v2 and v3 in the percentages defined in the virtual service.

[source]
----
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
----

Of the above 25 calls, 10 are for v1 (40%), 8 are for v2 (32%) and 7 are for v3 (28%). The distribution percentages become more accurate the more messages are sent. When 1000 calls were made in a test activit the percentage distribution was v1 : 49.3%, v2 : 31.0% and v3 : 19.7%.

Switch to the Kiali browser view and wait until the traffic starts to appear. Onthe second to left drop down option menu at the top of the Kiali screen select the option "Requests percentage". This will show the breakdown of traffic similar to that which is shown below:

image::service-mesh-09.png[OpenShift topology view of micro-services]












